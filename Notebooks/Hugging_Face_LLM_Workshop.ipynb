{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itinstructor/JupyterNotebooks/blob/main/Notebooks/Hugging_Face_LLM_Workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C192SOmJS6lw"
      },
      "source": [
        "# Getting Started with Large Language Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHC-R-SDVvOV"
      },
      "source": [
        "## What is a large language model (LLM)?\n",
        "\n",
        "A large language model (LLM) is a type of artificial intelligence (AI) program that can recognize and generate text, among other tasks. LLMs are trained on huge sets of data — hence the name \"large.\" LLMs are built on machine learning: specifically, a type of neural network called a transformer model.\n",
        "\n",
        "In simpler terms, an LLM is a computer program that has been fed enough examples to be able to recognize and interpret human language or other types of complex data. Many LLMs are trained on data that has been gathered from the Internet — thousands or millions of gigabytes' worth of text. But the quality of the samples impacts how well LLMs will learn natural language, so an LLM's programmers may use a more curated data set.\n",
        "\n",
        "LLMs use a type of machine learning called deep learning in order to understand how characters, words, and sentences function together. Deep learning involves the probabilistic analysis of unstructured data, which eventually enables the deep learning model to recognize distinctions between pieces of content without human intervention.\n",
        "\n",
        "LLMs are then further trained via tuning: they are fine-tuned or prompt-tuned to the particular task that the programmer wants them to do, such as interpreting questions and generating responses, or translating text from one language to another."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMdOTv-uVvOW"
      },
      "source": [
        "## Transformers in a Nutshell\n",
        "\n",
        "A **transformer** is a neural network architecture based on the concept of **attention**.\n",
        "* They're what make LLMs work - behind ChatGPT et al.\n",
        "* You feed a lot of text data into the neural network, and it learns which words relate to other words\n",
        "\n",
        "\n",
        "<div>\n",
        "    <center>\n",
        "        <table>\n",
        "            <tr>\n",
        "                <td><img src=\"https://github.com/ericmanley/LLM4CSCurriculumWorkshop/blob/main/images/simple_self_attention.png?raw=1\" width=400px></td>\n",
        "                <td><img src=\"https://github.com/ericmanley/LLM4CSCurriculumWorkshop/blob/main/images/attention_vis1.png?raw=1\" width=300px></td>\n",
        "            </tr>\n",
        "        </table>\n",
        "    </center>\n",
        "</div>\n",
        "\n",
        "\n",
        "*image source:* Speech and Language Processing Fig. 10.2, https://web.stanford.edu/~jurafsky/slp3/10.pdf\n",
        "\n",
        "*image source:* from the original paper on transformers - **attention is all you need** https://arxiv.org/pdf/1706.03762.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngHVQiNEVvOX"
      },
      "source": [
        "## Why transformers?\n",
        "\n",
        "Unlike previous neural network architectures, they can be trained *in parallel*.\n",
        "\n",
        "LLMs use big models (take lots of words as input, encodings for lots of word senses, lots of layers for extracti.ng high level features of text, trained on massive amounts of text)\n",
        "\n",
        "<div>\n",
        "    <center>\n",
        "        <img src=\"https://github.com/ericmanley/LLM4CSCurriculumWorkshop/blob/main/images/transformer_encoder_decoder.png?raw=1\" width=300px>\n",
        "    </center>\n",
        "</div>\n",
        "\n",
        "*image source:* Hugging Face NLP Course - **How do transformers work?** https://huggingface.co/learn/nlp-course/chapter1/4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY7DSbgQVvOX"
      },
      "source": [
        "## Installing the Hugging Face `transformers` library\n",
        "\n",
        "Hugging Face transformers library is already installed in Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOav56wCVvOY"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m0TSiYrVvOY"
      },
      "source": [
        "### What is Hugging Face?\n",
        "\n",
        "Hugging Face is a private company\n",
        "* Founded in 2016 by French entrepreneurs Clément Delangue, Julien Chaumond, and Thomas Wolf\n",
        "* Based in New York City\n",
        "\n",
        "Provide popular free, open-source libraries for natural language processing (and other) tasks\n",
        "\n",
        "Host *hundreds of thousands of models* that you can use in your own programs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7nJvuYQVvOY"
      },
      "source": [
        "## A first tranformers program: the sentiment analysis pipeline\n",
        "\n",
        "**Sentiment analysis** attempts to identify the overall feeling intended by the writer of some text\n",
        "\n",
        "The creators of this model **trained** it on lots of examples of text that were labeled as either *positive* or *negative*\n",
        "\n",
        "A **pipeline** is a series of steps for performing **inference**\n",
        "* tokenize and preprocess the input text (more on this later)\n",
        "* ask the model for a prediction\n",
        "* post-process model's result and turn it into something you can use\n",
        "\n",
        "\n",
        "<div>\n",
        "    <center>\n",
        "        <img src=\"https://github.com/ericmanley/LLM4CSCurriculumWorkshop/blob/main/images/full_nlp_pipeline.svg?raw=1\" width=600px>\n",
        "    </center>\n",
        "</div>\n",
        "\n",
        "image source: https://huggingface.co/learn/nlp-course/chapter2/2?fw=pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byblL8JJVvOY"
      },
      "source": [
        "* We *are* specifying the kind of task: `sentiment-analysis`\n",
        "* We *are not* asking for a specific model, so it picks one of many it has by default\n",
        "* The first time you do this, it will have to download the model - this can take some time depending on your network connection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pwf8spqVvOZ"
      },
      "outputs": [],
      "source": [
        "# Import the pipeline module from the transformers library\n",
        "from transformers import pipeline\n",
        "\n",
        "# Create a sentiment analysis classifier pipeline using the default pre-trained model\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Enter text to be classified\n",
        "text = \"I love how easy it is to build sentiment-aware applications with the transformers library!\"\n",
        "\n",
        "# Use the created classifier to analyze the sentiment of the given text\n",
        "results = classifier(text)\n",
        "\n",
        "# Print the sentiment analysis results\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YDCStDfVvOa"
      },
      "source": [
        "**Test it out:** Try changing the input to get different labels/scores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pipeline module from the transformers library\n",
        "from transformers import pipeline\n",
        "\n",
        "# Create a sentiment analysis classifier pipeline using the default pre-trained model\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Enter text to be classified\n",
        "text = input(\"Enter text to classify: \")\n",
        "\n",
        "# Use the created classifier to analyze the sentiment of the given text\n",
        "results = classifier(text)\n",
        "\n",
        "# Print the sentiment analysis results\n",
        "print(results)"
      ],
      "metadata": {
        "id": "RDxO0HIvtqbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHGUrvPBVvOa"
      },
      "source": [
        "## Activity: Specifying a model\n",
        "\n",
        "Now try asking for a specific model.\n",
        "\n",
        "Replace one line of code in your earlier example.\n",
        "\n",
        "You can find out more about this model by checking out its model card: https://huggingface.co/SamLowe/roberta-base-go_emotions\n",
        "\n",
        "What are some things you notice about this model that are different than the first one?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OE_cAJ2WVvOa"
      },
      "outputs": [],
      "source": [
        "classifier = pipeline(\"sentiment-analysis\", model=\"SamLowe/roberta-base-go_emotions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO-u82QPVvOa"
      },
      "source": [
        "## Activity: Explore additional models\n",
        "\n",
        "Go to the Hugging Face models page: https://huggingface.co/models\n",
        "* Click `Text Classification`\n",
        "* Find another model that looks interesting to you and try it out\n",
        "* You might be able to find models for spam detection, fake news detection, topic classification, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpzUieZRVvOa"
      },
      "source": [
        "## What about sequence-to-sequence models?\n",
        "\n",
        "The transformers library has models for generating output sequences - long text as input and output\n",
        "* summarization\n",
        "* translation\n",
        "* question answering\n",
        "\n",
        "Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xypzxZfdVvOd"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6GTVSwBVvOe"
      },
      "outputs": [],
      "source": [
        "# article copied from https://www.npr.org/2024/04/02/1242197022/biden-xi-jinping-call-china\n",
        "example_news_article = \"\"\"\n",
        "BEIJING and WASHINGTON, D.C. — President Biden and Chinese leader Xi Jinping held what a senior Biden administration official dubbed a \"check-in\" call on Tuesday, marking the first conversation between the leaders since their face-to-face meeting in California in November.\n",
        "The latest thorn in Taiwan-China tensions: pineapples\n",
        "World\n",
        "The latest thorn in Taiwan-China tensions: pineapples\n",
        "\n",
        "The call touched on everything from Taiwan to the situation on the Korean Peninsula, artificial intelligence and Russia's war in Ukraine.\n",
        "\n",
        "According to the Chinese readout, Xi told Biden strategic awareness \"must always be the first 'button' to be fastened\" in bilateral ties. The Chinese leader also elaborated his position on issues concerning Hong Kong, human rights and the South China Sea, the readout says.\n",
        "Taiwan's election was a vote for continuity, but adds uncertainty in ties with China\n",
        "World\n",
        "Taiwan's election was a vote for continuity, but adds uncertainty in ties with China\n",
        "\n",
        "The Chinese leader warned again that the \"Taiwan issue\" is an \"insurmountable red line\" in bilateral ties. Xi also urged Biden to \"translate\" his commitment of not supporting \"Taiwan independence\" into concrete actions, according to the readout.\n",
        "\n",
        "Biden, in the call, emphasized the importance of maintaining peace and stability across the Taiwan Strait and the rule of law and freedom of navigation in the South China Sea, according to a White House readout.\n",
        "\n",
        "The two leaders also discussed the global geopolitical situation. Biden, according to the White House, raised concerns over China's support for Russia's defense industrial base and its impact on European and transatlantic security. He also emphasized Washington's \"enduring commitment\" to the complete denuclearization of the Korean Peninsula.\n",
        "\n",
        "Tuesday's call was the first time Biden and Xi have talked since they met in northern California in November. There, they agreed on a range of steps to try to prevent increasingly fraught U.S.-China ties from slipping into conflict, including more frequent contact at the leader level, between militaries and beyond.\n",
        "\n",
        "Ahead of the call, a senior administration official told reporters the conversation would not represent a change in U.S. policy toward China, and competition remains a key feature.\n",
        "\n",
        "\"Intense competition requires intense diplomacy to manage tensions, address misperceptions and prevent unintended conflict. And this call is one way to do that,\" said the official, who spoke on condition of anonymity as he was not permitted to speak on the record.\n",
        "\n",
        "Biden raised perennial U.S. concerns about China's \"unfair trade policies and non-market economic practices,\" according to the White House readout — an issue that will be front and center when Treasury Secretary Janet Yellen visits China later this week.\n",
        "\n",
        "The president also reiterated to his Chinese counterpart that Washington will continue to \"take necessary actions to prevent advanced U.S. technologies from being used to undermine our national security, without unduly limiting trade and investment,\" the White House readout said.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEBfwj4zVvOf"
      },
      "outputs": [],
      "source": [
        "summary = summarizer(example_news_article)\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Translate to Russian"
      ],
      "metadata": {
        "id": "unkIo8XxGHLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacremoses\n",
        "# Import the pipeline module from the transformers library\n",
        "from transformers import pipeline\n",
        "\n",
        "# Create the translation pipeline for English to Russian with the Helsinki model\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-ru\")\n",
        "\n",
        "# Enter text to be translated\n",
        "text = input(\"Enter text to be translated: \")\n",
        "\n",
        "# Use the created translator to translate the text\n",
        "translated_text = translator(text)\n",
        "\n",
        "# Print the translated text\n",
        "print(\"Translated Text:\", translated_text[0]['translation_text'])"
      ],
      "metadata": {
        "id": "XglS3190Fb-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocdfd3BpVvOf"
      },
      "source": [
        "## What about chat bots?\n",
        "\n",
        "Chat bots need models that have been trained on conversational text.\n",
        "\n",
        "To get the next response in a conversational thread, you need to pass in the entire conversation up to that point.\n",
        "\n",
        "Models often use special tokens like `<s>` and `</s>` to indicate where a sequence begins and ends, but it is different for different models: https://huggingface.co/docs/transformers/en/model_doc/blenderbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHSx1Dv8VvOf"
      },
      "outputs": [],
      "source": [
        "text_gen = pipeline(\"text2text-generation\", model=\"facebook/blenderbot-400M-distill\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_Zuw9pKVvOf"
      },
      "outputs": [],
      "source": [
        "conversation = \"<s>What is computer science?</s>\"\n",
        "result = text_gen(conversation)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gtcjpr5-VvOg"
      },
      "outputs": [],
      "source": [
        "conversation += \"<s>\"+result[0][\"generated_text\"]+\"</s>\"\n",
        "conversation += \"<s>Is it only related to math?</s>\"\n",
        "result = text_gen(conversation)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSb3ykP8VvOg"
      },
      "outputs": [],
      "source": [
        "conversation += \"<s>\"+result[0][\"generated_text\"]+\"</s>\"\n",
        "print(conversation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovkjZQgsVvOg"
      },
      "source": [
        "## What about data?\n",
        "\n",
        "Hugging Face also hosts lots of useful data sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OFksXAjVvOg"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MB5byKVVvOh"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"dair-ai/emotion\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdBD4NP2VvOh"
      },
      "outputs": [],
      "source": [
        "print(\"The first text in the dataset:\",dataset[\"test\"][\"text\"][0])\n",
        "print(\"The first text in the dataset:\",dataset[\"test\"][\"label\"][0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtkfVfnyVvOh"
      },
      "source": [
        "You can investigate the meaning of the label by zooming in on the `features` attribute of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87tUkkg6VvOh"
      },
      "outputs": [],
      "source": [
        "dataset[\"test\"].features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEXkioVtVvOh"
      },
      "outputs": [],
      "source": [
        "dataset[\"test\"].features[\"label\"].names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJP42xAEVvOi"
      },
      "outputs": [],
      "source": [
        "dataset[\"test\"].features[\"label\"].names[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9poly9sVvOi"
      },
      "source": [
        "## What about large models?\n",
        "\n",
        "Large models take a lot of resources to work with\n",
        "\n",
        "Many large models have smaller cousins that can be used for test purposes\n",
        "\n",
        "For example, the T5 model comes in different sizes, ranging from 60 million parameters to 11 billion: https://huggingface.co/google-t5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_EM48NvVvOj"
      },
      "source": [
        "## Resources\n",
        "\n",
        "Free NLP Textbook: Speech and Language Processing by Dan Jurafsky and James H. Martin\n",
        "* https://web.stanford.edu/~jurafsky/slp3/\n",
        "* great for theoretical and intuitive understanding of concepts\n",
        "\n",
        "Hugging Face NLP Course: https://huggingface.co/learn/nlp-course/\n",
        "* great for engineering/implementation\n",
        "\n",
        "Course Materials: https://github.com/ericmanley/F23-CS195NLP\n",
        "* Natural Language Processing course for undergrads that includes lots of implementation\n",
        "* Includes Jupyter Notebooks like this one\n",
        "\n",
        "Fine-Tuning Models for new data\n",
        "* Hugging Face fine-tuning chapter: https://huggingface.co/learn/nlp-course/chapter3/1\n",
        "* From my NLP course: https://github.com/ericmanley/F23-CS195NLP/blob/main/F7_1_TransferLearning.ipynb\n"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}